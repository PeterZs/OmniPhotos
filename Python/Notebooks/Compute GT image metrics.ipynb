{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import csv\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.metrics import structural_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2, max_value=255):\n",
    "    \"\"\"\"Calculating peak signal-to-noise ratio (PSNR) between two images.\"\"\"\n",
    "    mse = np.mean((np.array(img1, dtype=np.float32) - np.array(img2, dtype=np.float32)) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    return 20 * np.log10(max_value / (np.sqrt(mse)))\n",
    "\n",
    "# calculate_psnr(gt_img, ours_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssim(img1, img2):\n",
    "    return structural_similarity(img1, img2, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_shifted_metric(function, img1, img2, max_shift=1):\n",
    "    max_value = 0\n",
    "    \n",
    "    for y_shift in range(-max_shift, max_shift + 1):\n",
    "        y_start = max(0, y_shift)\n",
    "        y_end = min(img1.shape[0], img1.shape[0] + y_shift)\n",
    "        for x_shift in range(-max_shift, max_shift + 1):\n",
    "            x_start = max(0, x_shift)\n",
    "            x_end = min(img1.shape[1], img1.shape[1] + x_shift)\n",
    "        \n",
    "            img1_shifted = img1[y_start:y_end, x_start:x_end]\n",
    "            img2_cropped = img2[:img1_shifted.shape[0], :img1_shifted.shape[1]]\n",
    "            \n",
    "            value = function(img1_shifted, img2_cropped)\n",
    "#             print(y_shift, x_shift, value)\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "\n",
    "    return max_value\n",
    "\n",
    "# max_shifted_metric(calculate_psnr, gt_img, ours_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = r\"G:\\OmniPhotos\\Data\\GT-Replica\\{dataset}\\cubmap_image\\image\\{dataset}_{index:04}_{side}.jpg\"\n",
    "output_path = r\"G:\\\\OmniPhotos\\progress\\results\\GT quantitative comparison\"\n",
    "comparison = \"Our method (GT inputs)\"\n",
    "ours_path = os.path.join(output_path, comparison, \"{dataset}-Replica-cubemaps-{index:04}_{side}.png\")\n",
    "\n",
    "datasets = ['apartment_0', 'hotel_0', 'office_0', 'office_4', 'room_0', 'room_1']\n",
    "cubemap_sides = 'FLRBUD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 0\n",
    "total_psnr = 0\n",
    "total_psnr_squared = 0\n",
    "\n",
    "with open(os.path.join(output_path, comparison +\" - PSNR.csv\"), 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "    csvwriter.writerow([\"Dataset\", \"Index\", \"Face\", \"PSNR\"])\n",
    "\n",
    "    for dataset in datasets:\n",
    "        dataset_count = 0\n",
    "        dataset_psnr = 0\n",
    "\n",
    "        print(dataset, end='')\n",
    "        for index in range(81):\n",
    "            print('.', end='')\n",
    "            for side in cubemap_sides:\n",
    "                ## Paths to images\n",
    "                gt_image_path = gt_path.format(**locals())\n",
    "                ours_image_path = ours_path.format(**locals())\n",
    "                \n",
    "                ## Load images\n",
    "                gt_img = imageio.imread(gt_image_path)\n",
    "                ours_img = imageio.imread(ours_image_path)\n",
    "\n",
    "                ## Compute metrics\n",
    "                psnr = max_shifted_metric(calculate_psnr, gt_img, ours_img)\n",
    "                \n",
    "                ## Log result\n",
    "#                 print(f\"{dataset} -- {index:02} -- {side} -- PSNR: {psnr:.2f}\")\n",
    "                csvwriter.writerow([dataset, index, side, psnr])\n",
    "                dataset_count += 1\n",
    "                dataset_psnr += psnr\n",
    "                total_psnr_squared += psnr * psnr\n",
    "                break\n",
    "            break\n",
    "\n",
    "        psnr = dataset_psnr / dataset_count\n",
    "        print(f'PSNR: {psnr:.2f}')\n",
    "\n",
    "        total_count += dataset_count\n",
    "        total_psnr += dataset_psnr\n",
    "        break\n",
    "\n",
    "mean_psnr = total_psnr / total_count\n",
    "stdev_psnr = sqrt(total_psnr_squared / total_count - pow(mean_psnr, 2))\n",
    "sem_psnr = stdev_psnr / sqrt(total_count)\n",
    "print(f\"PSNR: {mean_psnr:.2f} +/- {sem_psnr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot(1, 2, 1); imshow(gt_img)\n",
    "subplot(1, 2, 2); imshow(ours_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 0\n",
    "total_ssim = 0\n",
    "total_ssim_squared = 0\n",
    "\n",
    "with open(os.path.join(output_path, comparison +\" - SSIM.csv\"), 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "    csvwriter.writerow([\"Dataset\", \"Index\", \"Face\", \"SSIM\"])\n",
    "\n",
    "    for dataset in datasets:\n",
    "        dataset_count = 0\n",
    "        dataset_ssim = 0\n",
    "\n",
    "        print(dataset, end='')\n",
    "        for index in range(81):\n",
    "            print('.', end='')\n",
    "            for side in cubemap_sides:\n",
    "                ## Paths to images\n",
    "                gt_image_path = gt_path.format(**locals())\n",
    "                ours_image_path = ours_path.format(**locals())\n",
    "                \n",
    "                ## Load images\n",
    "                gt_img = imageio.imread(gt_image_path)\n",
    "                ours_img = imageio.imread(ours_image_path)\n",
    "\n",
    "                ## Compute metrics\n",
    "                ssim = max_shifted_metric(calculate_ssim, gt_img, ours_img)\n",
    "                \n",
    "                ## Log result\n",
    "                csvwriter.writerow([dataset, index, side, ssim])\n",
    "                dataset_count += 1\n",
    "                dataset_ssim += ssim\n",
    "                total_ssim_squared += ssim * ssim\n",
    "            break\n",
    "\n",
    "        ssim = dataset_ssim / dataset_count\n",
    "        print(f'SSIM: {ssim:.4f}')\n",
    "\n",
    "        total_count += dataset_count\n",
    "        total_ssim += dataset_ssim\n",
    "        break\n",
    "\n",
    "mean_ssim = total_ssim / total_count\n",
    "stdev_ssim = sqrt(total_ssim_squared / total_count - pow(mean_ssim, 2))\n",
    "sem_ssim = stdev_ssim / sqrt(total_count)\n",
    "print(f\"SSIM: {mean_ssim:.4f} +/- {sem_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute statistics from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_dir = os.path.join(output_path, \"computed\")\n",
    "\n",
    "for csv_filename in os.listdir(computed_dir):\n",
    "    total_count = 0\n",
    "    total_value = 0\n",
    "    total_value_squared = 0\n",
    "    \n",
    "    if csv_filename[-4:] != '.csv':\n",
    "        continue\n",
    "    \n",
    "    value_per_dataset = {}\n",
    "\n",
    "    with open(os.path.join(computed_dir, csv_filename)) as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "        next(csvreader)  # skip header\n",
    "        for row in csvreader:\n",
    "            dataset, index, side, value = tuple(row)\n",
    "            index = int(index)\n",
    "            value = float(value)\n",
    "\n",
    "            ## Skip images on the camera circle\n",
    "            if index in [0,1,7,8,16,35,45,64,72,73,79,80]:\n",
    "                continue\n",
    "            \n",
    "            ## We're ignoring this dataset as the scene is way too close to handle.\n",
    "            if dataset in ['office_4']:\n",
    "                continue\n",
    "\n",
    "            ## We're focusing on the views around the equator, as that's where people mostly look\n",
    "            if side in ['D', 'U']:\n",
    "                continue\n",
    "\n",
    "            value_per_dataset[dataset] = value_per_dataset.get(dataset, 0) + value\n",
    "\n",
    "            total_count += 1\n",
    "            total_value += value\n",
    "            total_value_squared += value * value\n",
    "\n",
    "    mean = total_value / total_count\n",
    "    stdev = sqrt(total_value_squared / total_count - pow(mean, 2))\n",
    "    sem = stdev / sqrt(total_count)\n",
    "\n",
    "    if \"PSNR\" in csv_filename:\n",
    "        # round to 2 significant digits\n",
    "        mean = np.round(mean, 2)\n",
    "        sem  = np.round(sem,  2)\n",
    "        print(f\"{csv_filename} : {mean:.2f} +/- {sem:.2f}\")\n",
    "    else:\n",
    "        # round to 3 significant digits\n",
    "        mean = np.round(mean, 3)\n",
    "        sem  = np.round(sem,  3)\n",
    "        print(f\"{csv_filename} : {mean:.3f} +/- {sem:.3f}\")\n",
    "#     for dataset, value in value_per_dataset.items():\n",
    "#         print(f\"  - {dataset}: {value/(total_count/len(value_per_dataset)):.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Format stats ready for LaTeX table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## all found files\n",
    "# all_files = os.listdir(output_path)\n",
    "# csv_files = [e for e in all_files if e[-8:] == 'SSIM.csv']\n",
    "# row_names = [e.split(' - ')[0] for e in csv_files]\n",
    "\n",
    "## rows in the same order as in Table 1 (for easier updating)\n",
    "row_names = [\n",
    "    'MegaParallax-cylinder-3m',\n",
    "    'MegaParallax-plane-3m',\n",
    "    'Parallax360-cylinder-3m',\n",
    "    #\n",
    "    'Our complete method',\n",
    "    'Our method (GT inputs)',\n",
    "    #\n",
    "    'No robust data term',\n",
    "    'No normalised residuals',\n",
    "    'Huber-depth-sres',\n",
    "    'Optimising depth (not inverse)',\n",
    "    'DIS flow',\n",
    "    'No flow (linear blending)',\n",
    "    #\n",
    "    'Low-res proxy',\n",
    "    'High-res proxy',\n",
    "    #\n",
    "    'Less smoothness',\n",
    "    'More smoothness', \n",
    "    #\n",
    "    'Fewer images (45-DIS)',\n",
    "    'Fewer images (30-DIS)',\n",
    "    'Fewer images (15-DIS)',\n",
    "]\n",
    "\n",
    "for row_name in row_names:\n",
    "\n",
    "    row_text = row_name.ljust(35) + \"&  ...  \"\n",
    "    \n",
    "    for metric in ['LPIPS', 'SSIM', 'PSNR']:\n",
    "        csv_filename = f\"{row_name} - {metric}.csv\"\n",
    "        \n",
    "        total_count = 0\n",
    "        total_value = 0\n",
    "        total_value_squared = 0\n",
    "\n",
    "        with open(os.path.join(output_path, csv_filename)) as csvfile:\n",
    "            csvreader = csv.reader(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "            next(csvreader)  # skip header\n",
    "            for row in csvreader:\n",
    "                dataset, index, side, value = tuple(row)\n",
    "                index = int(index)\n",
    "                value = float(value)\n",
    "\n",
    "                ## Skip images on the camera circle\n",
    "                if index in [0,1,7,8,16,35,45,64,72,73,79,80]:\n",
    "                    continue\n",
    "\n",
    "                ## We're ignoring this dataset as the scene is way too close to handle.\n",
    "                if dataset in ['office_4']:\n",
    "                    continue\n",
    "\n",
    "                ## We're focusing on the views around the equator, as that's where people mostly look\n",
    "                if side in ['D', 'U']:\n",
    "                    continue\n",
    "\n",
    "                total_count += 1\n",
    "                total_value += value\n",
    "                total_value_squared += value * value\n",
    "\n",
    "        mean = total_value / total_count\n",
    "        stdev = sqrt(total_value_squared / total_count - pow(mean, 2))\n",
    "        sem = stdev / sqrt(total_count)\n",
    "\n",
    "        if \"PSNR\" in csv_filename:\n",
    "            # round to 2 significant digits\n",
    "            mean = np.round(mean, 2)\n",
    "            sem  = np.round(sem,  2)\n",
    "            row_text += f\"&  {mean:.2f}$\\\\pm${sem:.2f}  \"\n",
    "        else:\n",
    "            # round to 3 significant digits\n",
    "            mean = np.round(mean, 3)\n",
    "            sem  = np.round(sem,  3)\n",
    "            row_text += f\"&  {mean:.3f}$\\\\pm${sem:.3f}  \"\n",
    "\n",
    "    row_text += \"\\\\\\\\\"\n",
    "    print(row_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
